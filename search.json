[{"title":"数学符号测试","url":"/%E5%85%B6%E4%BB%96/%E6%95%B0%E5%AD%A6%E7%AC%A6%E5%8F%B7%E6%B5%8B%E8%AF%95/","content":"对数学符号显示进行测试，正常情况下述的内容是能显示数学符号。\n微分相关设函数在的邻域内有定义以及在此区间内。如果函数的增量可被表示为，其中是不依赖于的常数，而是比高阶的无穷小，那么就称函数在点是可微的，且称作函数在点相对应自变量增量的微分，记作，即。\n\n  \n    \n      微积分第一基本定理\n\n    \n    \n      设 , 其中为连续函数，对所有的，定义函数，有\n\n则在闭区间连续，并在开区间可微，且对所有在开区间中的，有。\n\n    \n  \n\n\n  \n    \n      微积分第二基本定理\n\n    \n    \n      设有两函数，若满足以下条件：\n且是闭区间上的连续函数，是黎曼可积函数，则有\n也简记为：\n\n    \n  \n\n\n积分相关对定义在上的有界函数，振幅。\n对其进行分割有，，规定每一段的最大值和最小值有：规定每一段的振幅和宽度。\n所以，我们对该函数在该区间分割的上界和下界定义有：\n","tags":["数学","其他"]},{"title":"对25年的总结和对未来的调整","url":"/%E5%85%B6%E4%BB%96/%E5%AF%B925%E5%B9%B4%E7%9A%84%E6%80%BB%E7%BB%93%E5%92%8C%E5%AF%B9%E6%9C%AA%E6%9D%A5%E7%9A%84%E8%B0%83%E6%95%B4/","content":"写在前面的碎碎念最近是刚换了工作，在这份工作还没进入状态之前，也正好把这一整年的内容给回顾一下，顺便从当前工作(主要是大模型的应用方面(包含大语言模型和多模态模型))的视角来看对26年要做的一些事情做点方向性的讨论。\n结合当前的经济情况，当前的学术界和工业界，大概率会更加分化，正如一些人所讲述的那样，应用型研究要更与工业界的落地结合，但这一类工作本身并不需要有创新(业界主要看效果反馈)，所以也可能很难去发表论文；另一方面，学术界的研究受限于资源，场景和数据，所以应该更关注理论部分，虽然学术界本身有论文评价那一套体系，甚至能够自己旋转起来，但要想真的做出点内容，理论这一块应该是少不了的。\n对于业界的工作，其评价体系早已和业务指标相关，虽然最近也看到一些新闻说是，需要由企业承担一定的研究责任，但感觉至少短期内，由于惯性的存在，应该还是保持类似的业务指标为主的存在，如何工程化，如何在一些特定领域上的指标有提升，则成为了业界需要关心的问题。\n不过对于个人博客的内容来说，下一年关于业务的内容大概率不是主线内容，26年大概率主要还是针对当前的技术了解，熟悉(以各种 mini-,nano-,tiny- 为主)，跟踪新的技术，也同时花点时间去回过头去看看一些比较扎实的工作，顺带的再去做点可能做的补充性工作。\n对25年所做的工作总结从整体来看，25年(包括24年后半段)算是半个混乱的状态，但这个混乱的状态并不是由我所引起的，而是企业转型中所必然引发的混乱。或者说，企业在这之前本身算是一个稳定的状态，没有遇到太多的混乱的状态，所以也很难从中抓住什么有用的东西，毕竟很多东西一直发生变化，而如果只是盯着变化，把太多的资源和时间都在这个变化之中而没有找到那条主线，很容易对自身产生怀疑，这些对于时间，资源，方法，技术，人员配置要求都太高，甚至似乎陷入某种死循环：\n\n没有从变化中抓住重要的内容，就没办法往下走；而没办法往下走，就没办法跟上这些变化。\n\n从而不断地往后退，退到当前人员和资源所能够尝试做点内容的位置上。而对于之前的组织，其实一直一个主要目标是\n\n  \n    \n      主要目标\n\n    \n    \n      如何利用当前的**先进技术(大模型)**优化当前的某些流程。\n\n    \n  \n\n其实这个目标是可以解读出很多内容的：\n\n将当前先进技术还是看做一种优化内部流程的工具，而不是拓宽或者稳定业务。\n企业的重心也不在于拓宽业务，而在于减少成本。\n\n所以在这个背景下，那时候的主要工作方向，就是朝着如何优化一些流程逻辑出发。只不过，在真实具体往下优化的过程中，一方面优化这些流程本身就是重新以这一套思路再走一遍已经做过的事，但实际上这一块稍微是有一个悖论:\n\n  \n    \n      流程优化的成本悖论\n\n    \n    \n      流程优化，本质上是降低流程的成本(一般展示形式是以更高效形式执行该流程)，但是要优化已有的流程，仍然是需要成本的，甚至这种成本在初期投入会比执行当前流程的成本更大。\n为什么？在这里，我们可以用一个数学建模来简单理解这个问题。首先我们有搜索空间的假设，同时假设这里有一个任务，在做这个任务之前，我们并不知道这个搜索空间和可能性有什么，所以在前期，就是有什么就做什么，所以能够获得对应的做法和对应的效果。\n但现在，我们相当于又要重新去做这个问题，所以这个成本至少是：新的探索空间成本，试错成本，新一批人力成员的成本等等。\n\n    \n  \n\n那么在这样的背景下，主要做的事情自然就是两方面的事情：熟悉新技术和尝试利用新技术去“优化流程”，对于前者来说，大家都比较有热情，但是对于后者来说，大家全都小白，没有动力，这一点还是挺有意思的。在这个过程中，对于新的这一块，主要是模型部署与推理优化，而对于优化流程，则是软件工程。\n模型部署与推理优化为什么要做这一块的工作这实际上是一个很常见的需求，从实际应用来看，模型与外界交互的方式，在当前互联网技术背景下，主要还是通过服务(servers)来进行交互的，即知道某个ip和端口，通过get，post等方式进行信息传递交互。由于不知道用户什么时候对该ip和端口进行请求，所以该服务自然需要时时刻刻运行。\n在这里会有一些成本和具体实践上的考量。比如，前期为了快速验证功能可行性，我们可以快速实现一个最简单的版本去确定是这个功能以后，就能够上线了。而随着后续发展，用户访问请求越来越多，则开始考虑对相关服务进行优化。\n所以一般情况下，前期注重功能，而后期注重性能。那么对应当前的流程自然就是，前期为模型部署，后期为模型优化(包括效果优化和性能优化)。 \n模型部署模型部署，顾名思义，就是将模型部署成一个对应的服务。这在之前的也稍微聊过，在工作中，其主要的流程就是：\n\n确定模型，通过pytorch运行该模型，通过测试案例确定功能。\n服务开发，这主要有两部分，一部分是服务启动(主要是模型启动)，一部分是模型运行(负责接受用户请求，处理过程和返回处理结果)。\n\n而我这一年的工作，实际上大部分都是这一块的内容。这是因为，对于这一块，大家几乎都没有人知道什么情况，为什么？因为整个团队对于互联网这一块的技术几乎是比较欠缺(这一块又可以开另一个话题了)。\n所以，我今年的工作实际上分为两块：\n\n模型部署环境建设：包括容器化，资源调度，开发流程固定等。\n模型功能开发部署，包括各种模型的部署，主要以AIGC模型为主。\n\n前者是因为，多个模型背后的环境大部分相同，但有少部分类似，所以类似Docker这种容器化技术就出现了，可以在一些基础镜像上构建该模型的运行环境；而多个模型之间资源会争夺，以及多个设备之间是否能够协同调度等，当前可以采用k8s来进行构建。最后就是，不同的模型，由于模型参数比较大，基本形式正如上述类似，服务启动=模型启动，服务运行=模型接收请求，处理，返回。\n所以在这个过程中，为了了解模型部署，还熟悉了Torchserve, TritonServer等模型推理框架(2020年左右还是比较热门的，这里还有一个小插曲，在我以Torchserve为基础框架开发的时候，Torchserve已经停止维护了，为此我还稍微调研了一下推理框架的小插曲，能够看到在发展中，定位什么也是很重要的。)，在这个基础上扩展到ML System，甚至稍微到了当前比较热门的AI Intra领域。\n(推理)计算优化本来想直接叫做推理优化的，但我认为，这一块针对训练也是一样的思路，所以在这里就以(推理)时就按优化作为这个子标题。\n事实上，如果从服务功能开发的视角来看，模型部署完毕以后，实际上任务就已经结束了。但对于深度学习视角，这一块又和传统的服务不一样，是因为深度学习模型是一种“计算密集型”的任务，特别是现在大模型的背景下，模型运行是需要调用硬件进行大量计算，所以哪怕只是单纯运行一次任务，也需要比较多的时间进行计算，但是从服务的视角来看，用户感受是不太友好的，因为用户总是倾向，更快更好地服务请求，而时间越久，则越容易失去兴趣。\n所以这和传统的服务还不一样的是，深度学习模型哪怕针对一个用户进行优化，也是有价值的，因为这是能够降低访问延迟，减少用户等待，提升用户交互流畅感。\n为什么能够做这件事呢？这是因为大部分的模型的运行后端主要是pytorch(huggingface的后端也有pytorch)，pytorch本身也是用python做解释器，这就会产生大量地计算冗余。举个最简单的例子，在python中，不同的网络层可以被看做是很多个函数计算有：\n\n它需要依次计算每一层函数，将得到的结果传入下一层。但如果这些函数能够被复合(有常量合并，算式合并等)成一个函数，则该式子就可以重新写成：\n\n中比如(常量折叠)和可以合并成，其中，, 中间就减少了很多冗余计算。\n上述是针对本身的计算进行优化，这一块是关于模型计算的优化，大部分也叫做计算图，一些计算操作则叫做算子。另一方面python的运行效率本身低，从本质上来说就是硬件的利用率低，所以，我们还可以针对硬件也需要去优化，也就是编译(compile)。在pytorch的2.0版本以后，官方甚至为了加速训练和部署，自己也出了一套编译函数torch.comile，当然这些内容也不是横空出世，而是在1.0版本就有类似的工作，只不过在2.0被重视和重构，以及变得更好用了。\n在这里，由于当前主流的模型部署都在英伟达显卡上，所以我们经常会听到类似CUDA，算子这些名词，其实就可以理解是在CUDA上计算的时候，对当前模型不断地优化的一些操作。\n而在当今的模型参数巨大的情况下，不只是单张卡上的优化，多张卡上也需要优化，包括多卡、多机之间的通信，存储上的访问，等等，这些当前也逐渐被形成一种岗位——AI基建(AI Infrastructure, AI Infra)。\n这一块实际上，我感觉既可以看做是之前ML System(这一块是专门关心模型如何构建训练数据，如何从这些数据下训练出来，以及如何合理地部署在上体上)在大模型下受到传统基建，HPC和硬件发展的影响上逐渐诞生出来的一种岗位。后面有机会也会多去介绍这一块的内容，至少在大模型下，这一块的内容应该是很难避开的。\n传统软件开发(软件工程)而这一部分，实际上本身我并不是特别想做，做这一块，主要是感受，在该组织中，由于没有计算机基础建设，所以很多内容需要反复重新做，而这个桥梁目前还是软件工程。而由于之前都没有经验，所以这一块基本上是能够推就推，工期和效果都非常的紧张，导致一个人要做的内容特别地多，特别地夸张。\n当前我所干的相关的内容，也算是稍微感受了一下超全栈的体验，这个超全栈指的是，不只是开发技术本身，诸如，前端，后端(已经包括测试)，运维等，还包括产品，需求分析，项目控制等等，从理论上来说，已经可以算是某种一人成军。而且，在这边由于配合得不是很好，很多时候不只是一个项目一个人负责，大多数都是一个人负责好几个项目，当然也不是所有的项目都要“全栈”，但基本上什么都要知道。\n当然，我认为这个熟悉是很重要的一个环节，只不过，最后没有办法和时间将其转变成真正可用的软件服务，这是比较遗憾的一件事。不过，这一块也有类似的事情，或者说，软件开发处处皆是，并不需要在意一定要在某个地方才能做点什么。\n而至于项目本身，我认为，当前能够比较说得有价值的项目相对较少，或者说，大部分的项目还处在思想验证，demo阶段，还在落地上去碰一碰。\n当前对深度学习的总体判断也顺便，既然对25年做了一点总结，那么也稍微能够对深度学习领域做一点总结。顺便也对概念做一些澄清，对未来的发展做点个人所理解的预期预测。\n对机器学习整个领域的回顾上一年我并没有追踪热点，一方面是所处的环境，另一方面当前主要大模型能力上的迭代更新，没有本质上的范式转换。\n首先，我们能够明显区分机器学习和深度学习这两个概念。因为机器学习更侧重是机器如何学习，而深度学习是机器学习的某个子类，以多层感知机(Multilayer Perceptron，MLP)为主的技术路线。机器学习有其曾经热门的技术，比如聚类学习，支持向量机，集成学习(从大模型角度来说，集成学习是否也是一种大模型？)等。而深度学习，是在以MLP为典型的，有着前向传播和反向传播的形式上针对不同领域设计的所设计对应的模型。而从机器学习分类学范畴下，深度学习大部分还是有监督学习（supervised learning）的，这也是为什么当前的大模型，每一个环节都需要构造监督信号。\n至少从这个视角来看，当前的大模型并没有从根本上突破这一块，大模型只是在这个基础上去不断去整合当前的数据，所以大家期许，能够让模型通过大量地学习，学到这一个领域“真正的本质”。但说实话，我认为这是比较困难的(因为相关的数据本身还是需要通过人类生成出来再映射到模型身上，这之间就会产生信息损失，以及模型是否能够真正意义上习得这些数据也是一个问题)，所以数据的质量就成为了制约大模型的瓶颈。\n所以，具身智能(不一定是人类形状的机器人)，则是将数据获取作为一种机器本身应该掌握的能力去执行，这些机器要什么数据自己主动去获得就好了，只不过目前这一块肯定有很多困难。\n而从大模型的结构上来看，当前大语言模型最舒服的应用实际上还是“信息查询”，我认为是因为里面的结构由于是QKV，Q就是查询，K是模型的“知识”，V是知识的“整合”，\n\n  \n    \n      大语言模型舒适区\n\n    \n    \n      所以我们每一次去询问模型，本质上就是，通过我们的询问(Q)去匹配模型存储的知识(K)，然后再整合起来(V)输出出来。\n\n    \n  \n\n如果“Q”构造得足够好的，那么就能够得到我们想要的“K”，并且输出出来“V”。从这个角度来说，为什么模型会倾向认同用户，是因为它其实也不是在认同用户，而只是这样做能够匹配出最合适的信息，你想看到这些信息，它就给你匹配出来罢了。\n所以对比传统的搜索引擎，有类似的特征，比如大家都针对“Q”去匹配存在知识库的信息”K”，然后对“K”进行排序返回给用户展示，此时的“V”就需要用户自行筛选和完成。\n当前的矛盾或者说不舒服的点就在于，信息整合的“V”到底如何控制，如何自动化地完成，以及这一部分如果都能够自动完成，是否会代替很多人的工作。\n推导到当前的AI Agent，AI Agent就是尝试将“K”转换成不同的工具(调用方式)，通过对任务“Q”的拆解，尝试拆解任务流“Q1,Q2,…”进而用不同的“K1,K2,…”完成得到结果“V”。\n所以，从这个基础上，未来深度学习的研究应当是，对“QKV”结构的额外尝试，或者说，我们能够理解，为什么大语言模型备受关注，这可能是信息查询的红利仍在发光发热，以及对“QK”后的“V”到底能够做什么的一次尝试。而另一方面，当前的更进一步的探索，则是QKV形式上的探索：\n\nQ还能怎么变：Prompt工程，微调等。\nK还能怎么变：基础模型构建\nV还能怎么变：信息整合等\nQKV整体概念的变化：AI Agent等\n\n那么大语言模型就更有用了吗？我认为这仍然是比较困难，因为从上述的讨论来说，它并没有比之前的深度学习有更深入的突破，而且大量要做的内容仍然是数据本身(对于QKV的转换可能仍然是工程上的考量)，虽然现在存在“左脚踩右脚”的情况，也就是利用一些已经训练好的模型去“匹配”合适的数据。所以这有一个模糊地带，原始数据训练以后早已模糊了，通过这种匹配得到的数据，到底有多大程度值得信赖？\n对比“对比学习”和传统的数据增广来看，通过设计好的提示词来规范一批数据，这些数据的形式仍然是之前的该模型训练的数据中去“Q”出来的，从结构上来看，并没有出现没出现的数据（模型无法想象出自己没见过的内容），最多是数据的分布发生了改变，比如一些可能专业的内容的数据被大量地结构生成出来了。\n\n\n对当前领域发展的一个预测从这个角度来说，大模型实际上甚至并没有给深度学习“续命”，反倒从事实上给做硬件底层和基建的有了更多的空间，比如如何部署大模型，更好更稳定地训练大模型等。但是大模型从结构上并没有产生更多可以动的空间，大量地基于大模型的工作甚至只能在Prompt上，虽然很多社科类，文字类的工作受到了冲击，但是大模型本身能够做的并不多，甚至有时候成本代价很大，比如模型结构的改动，重新训练等等。\n短期(3-5年)通过Prompt，微调等方式，利用一些已经被训练好的模型进行数据提纯，在某一些领域上做得更好。在通用(大量)数据和少量高质量数据之间进行平衡，利用专有数据对一些领域做一些特殊化的产品。\n\n\n中期(5年以后)我认为还是要回到结构上的探索，只不过这种结构上的探索大概率也是要匹配领域的，成为领域特有的专有结构，类似CNN结构能够做图像这种标志。但更可能还是需要去探索一种基本方法论，类似软件工程的领域软件开发一般，能够形成领域特殊性。\n而Attention等相关的模型，就类似新时代的“数据库”一般，还能够继续做，往小做，就是变成自己的数据库；往大做就是类似搜索引擎网站，能够检索相关的信息。\n\n\n\n预期2026年可能会推进的一些内容所以基于上述的讨论，对自身当前状态的定位和环境的判断，再结合2025年了解和做的一些工作，感觉2026年会往这些方向熟悉和了解一下。\n大规模参数的深度学习当前我并不把大模型(Large Model, LM)新开一个分类，虽然它在学术和讨论上似乎已经成为一个被区分开来的分类，但从概念上其仍然只是深度学习模型的一个子集，并且并没有显著地和其他结构有明显的差异。\n所以在这里，它与传统深度学习模型之间最大的差异就是，参数规模巨大，在这参数规模巨大下，能够如何把这个模型给训出来，中间存在什么技术是需要去了解的。而在这个基础上，由于个人并没有那么多的资源，所以会以各种小的，mini, nano, tiny等方式去探索一个有对应特点的内容。\n而对于大模型所对接的业务，这一块在当前的岗位一定是会有大量的现实的任务去做，所以这一块我倒是并不担心有什么额外的问题。\n对于一些内容的深入说实话，本来这一块想写点阅读论文的，但是看着现代的论文似乎都没有阅读下去的欲望，所以这一块改成读一些比较有水平的内容。相较于跟踪前沿，我认为可能现在是时候是需要回头看，去重新理解之前的内容是否还有没有被解读出来的情况，更彻底地理解这些范畴之间的关系。还是认为自己的基础并不扎实，所以还有很多课是需要补的。\n","tags":["其他"]},{"title":"科研技能辅助当前方向前进","url":"/%E5%85%B6%E4%BB%96/%E7%A7%91%E7%A0%94%E6%8A%80%E8%83%BD%E8%BE%85%E5%8A%A9%E5%BD%93%E5%89%8D%E6%96%B9%E5%90%91%E5%89%8D%E8%BF%9B/","content":"碎碎念之前没有系统性地针对科研这一块进行梳理，是因为一方面之前读研的时候看了太多的论文需要去缓一缓，重新思考一下科研对自己的意义；另一方面，也是需要去换一个方向，因为之前主要是做的“推荐系统”，但是这个方向并不是我特别想要做的方向，所以只是堪堪毕了个业就结束了。\n而在新的方向上，同时也是当前学术科研中还算是稍微热门的方向——模型部署和推理方向。针对这个方向的前进，在一开始可以阅读很多相关经典的材料来快速入门，但是真正到这个方向比较关键的问题上，相关的资料一定是稀少的，其实这个问题在科研中是经常出现的，因为一般来说在学术中阐述的方向都是比较新的，也就是一般只能拿到一些文字描述，但具体如何在这个方向上推进则需要大量自己的思考和实验才能够解决。\n所以，在这里，重新对之前的科研方法做一定的梳理，尝试在当前的方向上去推进一些比较深入的研究。\n学术和科研目前主流认知来看，科研一般都是和学术，特别是学术圈(比如某某高校老师，某某研究院)紧密联系在一起，而在外界中，或者在个人中则很少和科研相关。当然在绝大学科中，特别是工科需要实际的仪器，比如医学药学、机械工程、生物化学等相关的方向，其科研过程就是通过对应的仪器在所在的领域中探索新的可能性或更好的效率。\n所以这一类学科的研究很大程度依赖对应的探测仪器，也很自然需要有专门的研究室和场地布置相关的仪器，甚至可以想象到，仪器的使用本身也需要成本也需要持续的支付对应的成本，所以很难以个人的方式开展相关的研究。\n在这里还可以额外说一点是，之前在知乎上回答一个关于仿真实验科研相关的问题，在这里还可以意识到一点是，相关领域底层的机制已经能够被数学模型比较精准地进行建模的时候，在仿真环境下处理是一种成本更低的方式。因为如果数学模型比较精准地刻画了领域相关的现象，在该仿真平台上进行操作得到的结果和现实对应的组件操作后得到的结果类似，那为什么不在仿真上去做相关的实验。至于文科相关的科研，由于本人主要是理工科相关的，所以没有多少经验，就不乱说话了。\n所以，这里就又引出一个问题，数学和物理在科研中的作用是什么。在这里可以简单地进行二分，数学建模(描述)和数学理论(关系)，前者是用数学形式化的符号对对应的内容进行描述，而后者是在这个基础上探索符号之间的关系。所以更进一步地，纯粹数学就是探索数学符号的数学，后续有相关的材料再进行深入的阐述。\n那么基于具体领域科研的基本形式的理解，再来理解学术圈其实就很简单，学术圈从某种角度来看就是组织一群人在这个领域上去探索新的内容，针对具体的内容在这里不再去说，总之，在这里应该理解，学术圈和科研在某种程度上是可以分离开来，而不需要特别深入学术圈也能够做科研。\n那么接下来，简单阐述一下尽可能摒弃掉学术的科研应该是一个什么样的形式。\n科研的基本形式从过程来看，学术圈中理工科的科研的基本形式是，看论文，做实验(工科)或者做题目(理科)，在已看论文的基础上发现新的内容并确定下来，此时就可以开始写论文进行论文上的投稿。\n而至于对应的工具，不管是大模型时代之前的文献管理工作，翻译软件，还是如今的大模型时代下直接全文翻译与阅读，其核心仍然没变，大体可以分为三个过程：\n\n知识输入\n领域探索\n知识输出\n\n1. 知识输入知识输入，最浅薄的理解就是，我去看领域相关的材料就是知识输入。不过，据我个人体会，我认为单纯看应该是不够的，而是要自己也去动手去做，才是一种真正的知识输入。\n就以深度学习领域的研究为例，当看完一篇比较好的论文的时候，并不是单纯看完就行了，甚至有可能是需要动手去重新把这一块重新走一遍才算是真正的知识输入。具体来说，可以按照以下步骤来执行”材料搜集”，”材料阅读和验证”，”材料化简和整理”。\n\n  \n    \n      材料搜集\n\n    \n    \n      在学术上则相对比较直接，就是从论文中来，这也是当前学术圈的主要目标，那就是——发论文，所以学术圈肯定是从论文中来，到论文中去。但以个人经验来看，一个领域中的材料是非常多，可能有课程，可能有书籍(专著)，可能有博客，代码，当然也有论文。所以针对一个领域的材料的搜集，一开始确实可以从论文中出发，但最后形成比较体系的内容的时候肯定不止论文。在这里只是简单地阐述这样的过程，材料的形式是很多的。\n\n    \n  \n\n\n  \n    \n      材料阅读和验证\n\n    \n    \n      这一阶段的目标是，针对相关的材料进行阅读，大概有这么几个阶段：\n\n初步阅读：材料过滤，很多材料可能就是标题相关，但内容是讲其他的内容，所以这一类材料是需要过滤掉。以及对该领域的材料有一个大致的认识。\n深入阅读：在已有阅读的基础上，对材料的重要性和难度进行一定程度的区分，这能够加快后续阅读的效率。\n进阶阅读：有一些内容，特别是理工科的内容不能只停留在阅读上，还需要与对应的器材，代码交互操作才能够真正在这个上面有理解。\n\n经过这样的流程，就是知识输入，而这样的流程并不是一个线性过程，是需要反反复复做的过程。\n\n    \n  \n\n\n  \n    \n      材料化简和整理\n\n    \n    \n      输出并不只有写论文的阶段，事实上，在阅读和了解的阶段就可以进行输出。只是在学术圈中，阅读和了解的阶段可以以“资料整理”的形式表述出来，比如综述，或者是一小块的知识阅读报告。在这一块，主要就是对之前的内容的一个回顾和梳理，很多论文可能重复的内容，在这里就可以做一点筛选。当然，形式并不只是综述，对相关内容做一点归纳总结也可以。\n\n    \n  \n\n\n2. 领域探索上一阶段从领域的视角来看，可以被视作“领域熟悉”，知道这个领域在当前圈中是一个什么样的状态，有什么进展，有什么成果，并且在上述的过程中，自己也熟悉过。\n那么在这个基础上，此时论文以及一些前沿的博客内容就会相对较好，因为他们是针对当前比较新的问题进行讨论和尝试，这实际上就是一个方向，甚至是一些可行的方向，因为能够被发表出来被大多数人看到，可以理解为这个方向当前是一个被视作有潜力的领域，大家都愿意在这上面花时间去努力，所以也可以在这个方向上去尝试，当然最后的判断仍然是个人。所以对于个人来说，要么跟着当前前沿主流大家讨论的方向去做，要么就是根据自己的判断去做。有时候这两者是统一的，自己的判断和主流方向是一样的也是可以的。\n所以，从不同的视角来看，会有不同的探索方向：\n\n学术的方向是从论文中出发的，其方向也一定学术论文的方向。\n但也可以从领域视角出发，领域可能还有一些新的问题更困难的问题，短期内无法出论文但是相对重要的内容，由个人判断也可以自主推进。\n甚至更远离学术的视角来看，从实际生产生活中出发，发现了一些问题，针对这些问题进行探索等。\n\n当确定方向以后，还需要确定其目的，比如深度学习领域的很多论文，其目的就是在该任务下做得更好；比如一些数学理论的论文，其目的就是继续找到相关领域上新的定理和结论；比如一些数值计算方向的论文，可能方向就是更高效且数值稳定地计算方程相关的任务。\n在确定方向和目的以后，就能够从两方面入手来讨论：\n\n当前已有的方法做到了什么程度，还有那些没有解决的问题？\n从领域来看，已有的方法告诉了我们什么消息，是否还有什么其他的信息可以利用？\n\n领域探索最困难的点主要是两点：\n\n如何判断出一个有价值的问题。\n如何针对该问题提出有效的解决方案。\n\n对于前者来说，我们对一个领域了解以后会有很多问题，但大多数的问题可能只是较为简单或者只需几步，甚至别人已经解决了的问题只是暂时没搜集到；而对于后者，一般有价值的问题往往也是难题，是一般方法没有解决的问题。\n目前针对这一块就是领域相关的问题，换句话说，到了这里，科研的游戏才算是正式开始，所以对这些内容，也在以后的进展中逐渐道出答案。\n3. 知识输出最后，在上述探索中探明了一些有价值的内容以后，就可以进行知识输出。实际上，上述知识整理的时候就已经可以有知识输出。所以在这里也可以简单做一个分类：\n\n知识整理的知识输出——对已有材料的个人化重复。\n领域探索的知识输出——对探索结论甚至是过程的描述。\n\n前者是对已有内容的重复，所以这要求写作的时候需要大量地引用相关的内容；而后者是对探索成果甚至过程的描述，所以相对较少，但是也要描述清楚，为什么，是什么，结果如何。\n未来博客内容的规划所以根据上述的从学术圈剥离出来的科研方法与当前个人方向的结合，未来就是在这边进行相关的内容的输出，输出的内容有：\n\n已有材料的个人重复性输出。\n个人探索过程的描述。\n\n\n  \n    \n      已有材料的个人重复性输出\n\n    \n    \n      具体来看，又可以分成两类：\n\n如果比较已有材料可能包括课程，书籍，论文、博客和代码等等，总之可能相关的内容就会在前面标定一个标号。\n如果是一个系列内容的总体概述，也就是类似综述，则就是以一个类别来进行标题。\n\n\n    \n  \n\n\n  \n    \n      个人探索过程的描述\n\n    \n    \n      这一块就更接近当前的论文，或一些探索性，创新性的博客的撰写。\n\n    \n  ","tags":["科研"]},{"title":"高维空间数据稀疏与模型性能的讨论","url":"/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%90%86%E8%AE%BA/%E9%AB%98%E7%BB%B4%E7%A9%BA%E9%97%B4%E6%95%B0%E6%8D%AE%E7%A8%80%E7%96%8F%E4%B8%8E%E6%A8%A1%E5%9E%8B%E6%80%A7%E8%83%BD%E7%9A%84%E8%AE%A8%E8%AE%BA/","content":"高维空间采样的困难度讨论在高维空间中，数据点的分布通常是比较稀疏的。想象在一个维的单位超立方体内随机撒下个点，其中每个点的坐标都在区间之间且独立同分布的。如果我们将这个区间划分为个等长的子区间，那么整个超立方体就会被分割成个小立方体。随着维数的增加，哪怕是数百万的数据点也不足以覆盖个小立方体中的每一个。换句话说，大多数立方体将是没有数据对应的，这种情况在高维空间是普遍存在的。\n为了确保每一个小立方体至少有一个数据点，我们至少需要样本量满足:\n这意味着样本样是随着维数指数级增长的。在现实应用中，数据的维数可能非常地高(例如一张  的灰度其维度就高达)，而可用的样本量通常远小于，因此，高维空间中数据的稀疏性是一个不可忽视的问题。\n图像和自然语言数据通常处于一个非常高维的空间。例如，一张的灰度图像就可以看做是一个维度的向量，而一个自然语言句子，如果使用维的词向量表示，那么个单词的句子就是一个维的向量。在如此高维的空间中，数据点天然是非常稀疏的。\n而一般情况下，对于的灰度图像来说，随机采样生成的图像都是非自然的图像，看不出任意语义，如雪花一样。有意义的自然图像只占据很小的一部分空间。同样地，在高维空间的自然语言空间中随机采样，生成的文本通常缺乏语法结构和语义连贯性，与自然语言文本有很大的不同。\n总的来说，高维空间中数据的稀疏性对机器学习提出了挑战，因为许多传统的机器学习算法依赖数据的局部性。然而，正如图像和自然语言的例子所示，高维空间中有意义的数据通常具有特殊的结构，并不是随机分布的。因此，机器学习的一个重要任务就是设计能够捕捉和利用这些结构的模型和算法，例如卷积神经网络（CNN）利用了图像的平移不变性，Transformer利用了自然语言的时序关系。这些专门设计的模型和算法使得我们能够在高维空间中有效地学习和生成复杂的数据。\n","categories":["深度学习理论"],"tags":["数学"]},{"title":"深度学习推理系统（一）：TorchServe快速入门","url":"/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%8E%A8%E7%90%86%E7%B3%BB%E7%BB%9F/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%8E%A8%E7%90%86%E7%B3%BB%E7%BB%9F%EF%BC%88%E4%B8%80%EF%BC%89%EF%BC%9ATorchServe%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8/","content":"为什么需要推理框架上一篇文章已经提到，当前很多应用都增加了深度学习功能，但深度学习模型的一个特点是，模型能力越强，需要的算力也越多。这和传统的提供互联网服务有类似但也有不同，互联网的服务是不得不通过网络方式进行，比如移动支付需要进行网络验证，网络游戏，需要通过服务器通信。\n而深度学习模型能力，其实可以不通过互联网的方式直接使用，但对于大部分的用户来说，为了使用模型能力本质上是使用背后的算力，所以不管是直接使用模型，还是使算力自主构建模型都只能通过服务的方式提供，前者直接通过访问模型厂商所提供的API服务，后者则需要自主购买算力服务。\n那我们从模型厂商的视角出发，模型厂商本质上背后是拥有一群算力资源将其部署对应的模型服务提供给用户，那么为了更高效地提供模型服务，比如多个用户的模型服务请求，能否合并到模型进行计算，从而提升计算效率；亦或是将模型计算进行压缩，以更低地成本进行模型推理从而提供低成本的模型服务。\n那么为了提供上述所说的模型推理服务，自然需要对应的组件，那就是推理框架，未来一段时间会逐渐介绍常用的推理框架：TorchServe，TFServe，Kserve，TritonServe，以及一些常见的推理框架。\n\n  \n    \n      PS\n\n    \n    \n      在写这篇推文的时候，TorchServe已经更新了一个公告，未来不会继续维护TorchServe这个仓库，感觉写着写着要给每一个曾经出现的推理框架进行一个一个祷告，但总之先开这个系列来介绍。\n\n    \n  \n\n为了澄清一下概念：首先推理系统&#x2F;本身是涵盖很多东西的，提供服务只是他对外所看到的一面，而如何提供服务，深度学习模型如何推理，背后需要用到推理引擎，还有现在的LLM大模型，VLLM的推理算法等，有时候还需要针对模型做优化，有模型结构上的优化，有基于硬件的模型计算优化等。\n总之这一块并没有那么简单，后续就是遇到了就会额外说一下。\n2 TorchServe的介绍与快速入门2.1 TorchServe的背景官方代码仓库：[链接](pytorch&#x2F;serve: Serve, optimize and scale PyTorch models in production)，实际上安装TorchServe是很简单的，它所需要的依赖很少，就是服务端的jdk-17和框架的一些基础依赖，不要求有推理引擎比如Pytorch，huggingface。\n根据个人的调研，其实TorchServe一开始在2020年4月份出场就不被大家看好，从目前的最新消息，已经公布不会再进行更新来看，确实如此，经过了不到5年的时间TrochServe更新到0.12版本就已经停止更新了。\n\n\n从个人的视角来猜测其被弃坑的情况，直接原因是团队对这一块的已经没有精力维护，后续的更新也只是维护这个框架的漏洞，但我个人的猜测更多是，在2020年的深度学习模型主要还是以小模型为主，而在2023年以后，大模型的兴起，使得之前这种基于小模型推理的框架很难适应大模型推理的到来，特别是，该框架在个人使用的过程中，他的推理引擎实际上可以用各种引擎，不止Pytorch本身。\n虽然叫做TorchServe，但实际上没有Pytorch作为引擎推理模型也是可以的，所以换句话说，虽然网上大部分材料说该框架限制在Pytorch引擎，但由于其本质上是启动Java作为服务端和python运行模型程序，而只需要符合TorchServe框架的模型推理规范文件即可。\n话不多说，开始介绍本文的主角TorchServe吧。\n2.2 TorchServe入门前的碎碎念如果是23年之前，我可能会以TorchServe的官方Get Start进行介绍并快速入门TorchServe。\n现在的“不再积极维护”其实也可以预见，相关的资料可能存在与当前版本对不上的情况，这就导致Github的教程实际上和官网Pytorch的教程是存在偏差的，具体来说，是因为后续更新中增加了一个安全策略，使得一些命令不能直接使用，所以最终导致的结果就是无法直接调用模型服务。\n此外，由于之前在2020年左右，深度学习领域主要还是以小模型为主（其特点有，占用显存小，可以做batch多个输入合并计算等特点），所以利用TorchServe开发模型的思路主要是以小模型为主，比如教程所述的图像分类的模型，通过torch-model-archiver将其压入.mar文件，方便在后续的torchserve中启动。\n但是在2023年以后，或者说，深度学习存在一个特点是，当模型参数越多的时候在有充足的数据下是能够越做越好，虽然能够越做越好，但存在的一个问题是：模型也越来越大，所以如果你在2023年入门推理框架，并且选择了TorchServe，那么你甚至不能按照当前的教程直接部署大参数的深度学习，比如3B，7B，13B等，因为这些模型文件本身就有几G，导致你在构建.mar时候，由于本质上.mar是将模型文件压缩在.mar文件里面以及在后续部署的时候将.mar解压执行对应的文件。这就导致，不仅.mar文件特别大移动困难，且在部署的时候，还需要从.mar中解压出对应的模型文件，这需要大量的时间。\n所以如果是2023年以后再来入门TorchServe，就根本不能从.mar文件出发，那应该如何做才能部署大参数模型呢？其实TorchServe在github仓库中给出了一些解决方案，因为TorchServe已经是支持大参数模型的构建，比如扩散模型，比如LLM，所以我们仍然能够通过TorchServe构建大参数模型的推理服务。\n接下来就是介绍一个快速入门的方式，不得不说，在写这份入门经验，刚好看到TorchServe更新不再积极维护，或许这份入门教材可以生存很久。\n2.3 TorchServe的快速入门与开发指南在这里以TorchServe官方所提供的案例huggingface_Transformers作为例子快速入门与开发：案例代码。同时，通过这份案例就能够知道，为什么TorchServe本身并不限制Pytorch作为推理引擎，事实上它是支持其他深度学习引擎比如huggingface等。\n首先，从这份例子以及README.md文档能够了解如何开发，首先，该模型是一个Transformer模型，该模型支持多个功能，比如序列分类、QA、Token分类和对话等功能，但是在部署的时候，只能选择一个模型功能，为什么呢？\n这就要说到，TorchServe真正的处理逻辑是带handler的python代码文件，里面已经说清楚了该模型的处理逻辑，而model-config.yaml则配置模型的参数文件，通过加载配置文件就已经确定了当前模型的功能，比如这份文档的默认参数配置：mode: sequence_classification。\n换句话说，我们在开发我们的模型的时候，主要就是符合handler.py的形式，通过torch-model-archiver命令将我们的模型文件打包即可。\t那么首先我们先来看给出案例的handler是什么？这里列出handle.py必要的形式：\nfrom ts.torch_handler.base_handler import BaseHandler# 基础库加载class TransformersSeqClassifierHandler(BaseHandler):    def __init__(self):        &#x27;&#x27;&#x27;        这里是整类的初始化，主要是做参数上的初始化，可以省略        &#x27;&#x27;&#x27;    def initialize(self, ctx):        &#x27;&#x27;&#x27;        这里是服务的初始化，其中ctx就是传入控制模型的参数。        ctx读取的是目录下指定的配置文件信息config.yaml        通过该配置信息就能够控制模型，包括模型的worker、batchsize，以及模型本身的自定义参数。        定位：通过配置信息初始化模型服务。        &#x27;&#x27;&#x27;    def preprocess(self, requests):        &#x27;&#x27;&#x27;        这里是模型的预处理，都是也是请求传入的接口。        requests与python自带解析API请求的requests是类似的，传入的是字典，通过API固定下来。        定位：对用户请求进行预处理。        &#x27;&#x27;&#x27;        return # 返回处理结果，会抵达下面的inference函数    def inference(self, input_batch):        &#x27;&#x27;&#x27;        这里部分是模型推理部分，input_batch就是预处理函数处理以后所返回的结果。        所以经常，如果我们所使用的引擎比如pytorch，为了减少计算，比如梯度等加快推理，所以在这里就可以使用no_grad等函数进行包装。        定位：对请求进行模型推理。        &#x27;&#x27;&#x27;        return inferences    def postprocess(self, inference_output):        &#x27;&#x27;&#x27;        定位：对推理结果进行后处理，返回给用户        &#x27;&#x27;&#x27;        return inference_output\n通过上述的handler.py的关键形式，就能够快速理解TorchServe每一个服务的处理逻辑，而开发的时候也可以按照这样的逻辑进行开发，对每一个用户请求进行前处理，模型推理以及后处理三阶段进行处理。\n接着构建好你的模型处理逻辑以后，就需要将其进行打包，以便后续模型启动的时候能够识别模型处理逻辑文件，此时使用的就是model-archiver进行打包，通过该命令能够将相关的文件进行打包处理。\nmodel-archiver的命令参数含义在链接可以看到。注意到archive-format参数，有四种选择，就可以选择no-archive选项，虽然进行打包了但并没有真的进行压缩，该参数实际上只会输出一个文件夹，而该文件夹实际上就是之前内容的复制，从这里可以看出，如果使用其他选项打包成单独压缩文件，本质上就是将这些文件进行整理打包以不遗漏组件能够快速启动，有一种文件版的docker镜像的样子。\n从docker的视角来看，此时就相当于将程序必要的文件进行整理与打包，在后续的启动中能够完整启动。如果是小文件，这一点没有问题，但是当我们的模型文件特别大的时候，哪怕使用了压缩都需要很长的时间，这可能就不是一个很好地方式，类似docker也不会将数据文件打包进入docker镜像。\n那么打包以后，我们就可以利用trochserve命令启动从而执行我们的逻辑函数，进而部署我们模型以提供服务。TorchServe命令本身也有一些配置文件，需要配置，具体和后面的略微进阶一块说。\nTorchServe的API提供三种方式，默认端口是8080和8081，其中8080为模型推理端口，8081为模型管理端口，具体可参考文档：inference_api和management_api。\n作为基础入门就已经可以结束了。\n2.4 略微进阶如果只是完场上述的流程，那么只是利用了这个TorchServe开启了一个模型，如果仅此而已，那么与自定义的Fastapi或者Flask然后再部署对应的模型其实没有本质上的区别。可能会说，TorchServe是不是提供了模型优化，比如可以使用torchscript或者torch.compile对模型进行编译从而加速？亦或是采用onnx，torch-TensorRT对模型加速等等，所以使用这个框架就能够得到更好地性能？\n事实上，上述的模型优化，在Fastapi和Flask上依然可以使用，所以这并不是这个框架的特点。这也是为什么个人认为，从这个框架入手是一个相对平缓的方式。这个框架除了提供一般的组件，比如模型打包，规范API等功能，更重要一点也是提供了规范编写模型处理服务的框架，即handler.py的文件中的类handler。\n除此之外，自然该框架还有其他的特点：\n\n  \n    \n      推理框架所提供的特性\n\n    \n    \n      \n模型多副本worker。为了缓解用户请求的需求量，我们可以简单地启动多个模型副本为用户提供服务，且用户请求能够较好地分配到不同的服务上。单纯使用Fastapi和Flask实现起来就会比较复杂，是因为这是超越Fastapi和flask的逻辑，他们只负责一个服务，而无多服务之间的调度逻辑。\n\n合并请求。有一些深度学习模型，实际上是可以一次性处理多个请求需求，比如图像分类服务，多个图片通过预处理进行变换成同大小的图片，就可以让模型一次性处理多张图片共同返回请求从而提高模型本身的吞吐量。\n\n在用户请求较多的时候，通过判断请求时延来推断worker的负载情况，从而自动伸缩对应的worker数量，以缓解短时间来的请求过多的任务，比如休息时间请求较少，而工作时间请求较多的情况。\n\n自动选择GPU启动模型。很多时候，我们的模型都需要GPU才能够启动，而TorchServe提供一个自动选择GPU的方式来启动我们的模型，一般都是均匀分配的，所以能够平缓地使用GPU资源。\n\n\n\n    \n  \n\n那么如何控制，有什么参数，实际上上述的例子已经有告诉大家了，可以看这个来获得所有参数的含义，可以参考：链接。\n在这里主要是做一个提醒：有一些配置是启动TorchServe的配置，而有一些配置是针对模型本身的配置，这两点是需要分清楚的。\n3 题外话其实本来是想仔细写好TorchServe的入门介绍的，因为就我个人经验来看，TorchServe应该是最简单以及最快能够体验并且理解推理系统的作用的。同时其安装比较简单，哪怕不使用docker也能够快速安装，因为它本质上是与其他推理引擎分隔开来的。\n甚至我们可以来讨论一下，为什么TorchServe要停止更新了：个人的观点——从一开始就是爹不亲妈不爱的状况。\n首先，虽然TorchServe名义上是在Pytorch下面的一个代码库，为Pytorch服务，但它本身也可以脱离Pytorch的推理引擎，那么从另一方面来说，框架本身并没有和Pytorch很好地融合起来（比如推理加速，更底层地优化等），而只是提供了一个基础的推理特性，这个特性在其他的推理框架上都存在，甚至做得更好，\n其次，推理框架一开始的出发点是小模型的快速部署，做了模型打包，模型工作流，以及常见的模型类，分类，回归等，在现代大参数模型的背景下都没人关注。\n所以，最终迎来了自己终结（不再积极维护）的结局。\n但是，如果是想要入门推理框架，TorchServe作为一个拥有基础推理框架特性且安装简单。对于小白来说，快速熟悉框架特性是一个比较不错的选择。当然，作为生产力工具，其仍然面临自己的问题，比如多模型的部署，多个模型之间如何配合，以及上述的端口请求如何合并，多个模型的版本的管理（主要是以文件的形式管理）所提供的支持都是比较弱的，当然，我们也可以这么说，我们只是写好服务，而至于API请求，模型管理应该交给其他组件来做，我们只需要负责模型服务的逻辑已经提供一个约定好的访问请求范式就好了。这当然也没有问题。\n但从生产的角度，特别是当前的模型服务提供厂商，这些又是必须要解决的问题，所以TorchServe确实处在一个尴尬的状况，最终也确实再难以维系下去…\n","tags":["推理系统"]},{"title":"方向(部署与推理)的转变说明与整理","url":"/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%8E%A8%E7%90%86%E7%B3%BB%E7%BB%9F/%E6%96%B9%E5%90%91(%E9%83%A8%E7%BD%B2%E4%B8%8E%E6%8E%A8%E7%90%86)%E7%9A%84%E8%BD%AC%E5%8F%98%E8%AF%B4%E6%98%8E%E4%B8%8E%E6%95%B4%E7%90%86/","content":"前面的碎碎念之前主要是业务上需要针对模型部署做一些调研和实践。其实模型部署推理框架的概念，更像是DevOps（部署运维）的概念的延伸，而除了之前介绍的TorchServe之外，还有NVIDIA的Triton Server，Kubernet的Kserve，BentoML等，都是在这个上面提供相关的功能，或者说，我们从“微服务架构”来看，相关的模型服务就是一个个微服务。而另一方面，在大模型兴起的背景下，相关的模型推理框架，比如TorchServe实际上并没有针对大模型有更多的优化（至少vllm和现在的sglang都不是pytorch出的），也估计没有更多的精力来适配大模型的服务的部署，所以这一块的消退也是必然的。\n其实正如之前的TorchServe（现在已经停止更新了），但并不意味着模型推理系统就没有了，相反，对个人来说，更应该看到，相关的模型推理系统是针对一整个系统和框架来设定的，作为一个底层的框架选定一个即可，所以自然也没有什么更多的与深度学习相关技术的整合了。\n所以在做了上述推理系统框架的选定以后，接下来就是真正针对模型的部署了，以前没有深入这一块的时候还会认为，我有了模型推理框架以后，就能够自动地让模型抵达最高的计算效率，随着最近几个月的深入认识发现，事实上并没有这么简单，上述的推理系统框架只是提供了一个可以运行的环境，而在这个环境中模型如何进行计算是需要手动去操作的。\n模型部署与模型推理加速那么当前的任务就转变成，我们我们有一个模型如何让其在相关的模型推理系统框架上尽可能快速，准确且多的服务更多的人，这就是模型部署和模型推理加速的主要目的，更具体地，我们分别对模型部署和模型推理加速做一个直观的描述：\n\n  \n    \n      单模型部署\n\n    \n    \n      当前我们有个模型，我们将其部署在一个计算节点上，该节点可以是单个物理机器的单个计算设备（CPU，GPU，NPU，xPU），单个物理机器的多个计算设备（多GPU分布式部署），多物理机（多计算节点分布式部署）。\n\n    \n  \n\n\n  \n    \n      多模型部署\n\n    \n    \n      由于多人使用模型服务的时候会造成单模型压力，此时我们可以部署多个模型进行压力分担，或者叫做负载均衡，以此保证服务所提供的稳定性，响应时间等。\n\n    \n  \n\n\n  \n    \n      模型推理加速\n\n    \n    \n      针对一个模型，在已经部署的基础上，通过模型推理加速技术，在不改变模型精度或者仅降低一点精度的前提下，使得模型推理速度加快。\n\n    \n  \n\n接下来就在这里对上述的两个内容进行总体上的阐述，以及将相关的问题给简单罗列一下，有一个总体上的理解。\n模型部署概述从模型推理系统框架说起其实这一块是延续着之前TorchServe的模型推理系统框架的，只不过这里略微有点区别的是，模型推理系统框架除了单模型的多计算节点多副本部署之外，最大的作用就是能够作为一个系统管理底层的计算资源，模型调度(对不同用户访问频次进行感知，动态调整模型副本数量)。\n从这个角度来看，TorchServe确实也不适合作为“模型推理系统框架”的服务作为，因为它并不能感知用户的访问频率和使用量对其进行模型副本的调整，当然有其他的方式来做到，但是这样Torchserve也就可有可无的。事实上，我认为TorchServe想要做的创新可能主要是结合Pytorch.compile以及workflow这两个来组合小模型之间的快速部署和配合，但在大模型的背景下，一个模型就可以看很多事情，而不是很多模型协同干一个事情，也可以看出之前相关团队对技术发展的没有做好足够的判断。\n在这里，本文并不对模型推理系统框架作更进一步的介绍，而是停留在单个模型的模型部署上，特别地，就是针对单个模型的单副本部署。一般来说，主要有这么几个场景：\n\n边缘场景：基于ARM的CPU上、主流电脑x86的CPU上和主流电脑的GPU上(NVIDIA，AMD等)、一些专用芯片TPU，xPU上等。\n集群/数据中心场景：在多个计算节点上进行模型部署。\n\n具体来说，一般模型部署流程，首先在深度学习框架(比如Pytorch、TensorFlow等)上搭建好深度学习模型，并且利用数据和深度学习框架对这些模型训练训练完毕以后，就可以把模型结构和模型参数分离开来，对这一块部分进行模型部署。大部分情况下模型部署只需要模型前向传播的计算即可，少部分场景还可以通过运行过程中获取的数据进行模型的训练。前者叫做“离线训练”，数据都是模型非部署时候采集的对模型进行训练，在部署时不改变模型；后者叫做“在线训练”，模型部署上去的时候，同时采集数据，利用在线搜集的数据对模型进行训练。\n模型部署所思考的问题但是不管哪一种形式，模型部署和深度学习框架都脱离了，或者说，当一个场景确定使用某模型的时候，其训练方法和计算过程也被确定下来，而不需要再维持一种“模型开发”的组件，比如深度学习框架。所以在这个基础上，模型部署天然地带有运行环境轻便，或者说去掉了很多冗余组件的情况，比如你不需要带着一个深度学习框架来计算一个模型。甚至更极端地，我们完全可以通过将前向传播的过程用函数的方式固定下来(此时该程序是完全针对该模型定制化的程序)，使得该程序的体系尽可能小，这就是模型部署。\n当前主流模型部署框架有(并不全，只列举当前主流的框架)：\n\n\n\n框架\n地址\n简介\n支持平台\n\n\n\nONNX (Open Neural Network Exchange)\nGithub仓库\n微软开发的开放模型格式标准，可以实现不同模型框架之间的转换\n跨平台\n\n\nTensorRT\nGithub仓库\nNVIDIA开发的，针对NVIDAI计算设备的转换和优化\nNVIDIA-GPU\n\n\nOpenVINO\nGithub仓库\nIntel硬件高性能推理\nIntel-CPU、Intel-GPU、VPU\n\n\nMNN (Mobile Neural Network)\nGithub仓库\n阿里开发的，具有良好的通用性\nARM CPU、ARM GPU、X86 CPU、GPU等\n\n\nTVM (Apache TVM)\nGithub仓库\n深度学习编译器，支持多种后端硬件自动优化模型部署\n多种CPU、GPU和专用加速器\n\n\nmediapipe\nGithub仓库\nGoogle开源，构建多模态应用机器学习管道，提供预构建组件（如目标检测、手势识别）\n跨平台（移动、工作站、服务器）\n\n\n从上面可以看到，当前模型部署的框架主要想要解决的就是，从已有的深度学习框架训练出来的模型如何在不同(指定)的硬件平台上以该硬件平台上运行的方式进行模型计算，如果硬件平台提供高效的计算方式，特别是矩阵计算方式，则能够提高模型计算速度。\n简单来说，模型部署从编写代码到运行的时候可以看做，这一个程序脱离了之前的开发阶段，以一种精简的方式来进行运行，可能可以简单类比为JAVA程序能够在不同的硬件平台上运行，只要这个硬件平台能够运行底层的JAVA虚拟机。从上述主流的框架来看，可以针对移动端和边缘设备上部署，也可以针对特殊的设备比如NVIDIA设备进行部署。\n可以简单总结这里面的问题：\n\n模型开发所处的硬件平台并不是运行模型的硬件平台，需要适应部署的硬件平台。\n那么，在初始平台中所表示的模型，就需要转换成部署的目标硬件平台\nONNX就是解决了这种统一的表示(当然，最基本的表示仍然是模型公式，ONNX只是在计算机体系下如何进行模型的同一表示，所以其算子一直无法覆盖所有网络标识，也一直在更新)。\n\n\n\n模型推理加速概述接下来，在模型能够在任意的硬件平台部署的基础下，还需要思考一个问题如何让模型更快地进行推理，从实践经验来看，至少能够从两个视角来看一个深度学习模型：\n\n从深度学习模型领域上看，大量的深度学习模型的主要任务是对目标任务进行优化，但其中会产生大量的计算冗余。这已经在一些针对深度学习现象的研究中已经多次指出了。\n从高性能计算领域上来看，深度学习主要以矩阵计算为主(现在也在逐渐发展出稀疏的矩阵计算)，而一些计算上的融合，分块能够更高效地进行计算，从而能够加速模型推理。\n\n接下来，就针对这两个简单展开来讲讲，在后续的章节会进行大量地讨论。\n模型层面的加速最近，或者说从深度学习(多层感知觉, MLP)一开始，就伴随着参数冗余的现象出现。在这里，并不去深入讨论起机制的产生，但起现象是一直伴随的。所以从模型层面描述模型推理加速，最重要的一点就是找到深度学习模型中冗余的部分，更准确来说，在尽可能不降低模型性能的基础上减少冗余部分，这本身是能够使得模型推理计算加速的。\n相关的技术就有：\n\n剪枝\n量化\n蒸馏\n\n在这里只是进行简单的介绍\n\n  \n    \n      剪枝\n\n    \n    \n      对一个模型，有参数集合，其模型性能可以简单记为，在某任务下有性能，那么剪枝可以简单描述为：\n在保持性能不减少会略微减少的情况下，尽可能剪去更多的参数，从而使得模型能够运行得更快。\n\n    \n  \n\n从这个直接的描述来看，从另一个角度理解，剪枝就是找到这个模型中不怎么影响模型能力的参数，把这些参数给删去即可。\n\n  \n    \n      量化\n\n    \n    \n      和剪枝类似，参数的是由不同的数据类型标识，比如float64(double), float32(float), bf16等等，从实践经验上来看，很多模型在低精度上仍然具有比较好的性能，同时低精度的计算也会比较快，功耗低。\n\n    \n  \n\n量化从某种角度来说来看，可以看做是横切模型，或者说针对数据类型的“剪枝”。\n\n  \n    \n      蒸馏\n\n    \n    \n      模型蒸馏，从形式上来看，一般是一个做好预训练的较大的模型(较大的模型具有较强的拟合能力)通过蒸馏的方式让小模型的性能能够接近大模型，由于小模型本身的参数较少，所以运行较快。\n\n    \n  \n\n蒸馏学习也是满足上述模型存在冗余的假设，大模型中有大量的冗余参数，而小模型的参数较少同时又需要达到比较高的性能，是尽可能调动了所有的参数。至少，从实践来看，比起直接在数据集上训练，蒸馏能够得到更好地性能。同时，数据也被压缩了(存模型比存大量的数据集要少)。\n高性能计算层面的加速而从高性能计算角度来看，当前的深度学习模型主要以矩阵计算为主，并且最重要的，模型仍然是在当前的计算机体系中运行的，所以可以从针对矩阵计算优化，计算优化的角度来加速模型推理。\n在这里简单做一点原理上的解释：那就是尽可能利用计算上的空间局部性和时间局部性来加速计算，简单来说就是，尽可能减少通信，尽可能做更多的计算，尽可能压缩计算。\n而具体来看，在这里又有两方面的优化，一个是通用加速优化，也就是上述的矩阵计算的优化，还有一个是针对模型计算过程的优化，比如算子融合，计算图优化等操作。\n总结最后，对上述做一个总结。虽然看似是方向上的很大的转变，但实际上也是一步一步走过来逐渐认识到在更深层次还有这些需要去完善。\n未来的规划所以未来的方向，或者说更具体来说，针对模型部署来说，主要是针对模型推理加速这一方向来进行深入研究。具体来说，会有三方面的材料：\n\n领域相关的最新的论文、博客和技术报告。\n经典模型结构研究：有优化和加速价值的模型，其模型结构本身也是有价值的。\n基础内容的回顾：包括计算数学，深度学习，计算机体系还有高性能计算。\n\n额外再提一些相关内容在当前，针对大语言模型的部署，还有vLLM和sglang框架，其实这一块属于模型部署上，它的定位(没有深入地理解)我感觉可以定位为，单副本部署的多用户服务，简单来说就是单个模型能够尽可能为更多的用户进行，因为简单来看vLLM的PagedAttention是让不同的Attention进行分页，从而相同的能够一起计算，充分管理好内存碎片，假设在没有进行模型本身的优化情况下，它能够提供更多的用户服务。所以这一块可以看做是模型部署的一个工作。\n","tags":["推理系统"]},{"title":"深度学习推理系统（二）：TorchServe的深入与性能监控","url":"/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%8E%A8%E7%90%86%E7%B3%BB%E7%BB%9F/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%8E%A8%E7%90%86%E7%B3%BB%E7%BB%9F%EF%BC%88%E4%BA%8C%EF%BC%89%EF%BC%9ATorchServe%E6%80%A7%E8%83%BD%E5%88%86%E6%9E%90%E5%92%8C%E6%A8%A1%E5%9E%8B%E8%B0%83%E4%BC%98/","content":"前提纪要这应该是TorchServe系列最后一个(虽然总共也就两个)，而且因为TorchServe不更新了，所以哪怕是继续写推理框架系统，也大概率不会以TorchServe 作为讨论对象了。\n在上一篇中已经说到TorchServe的启动方式是以.mar打包方式进行模型服务的快速启动，但在当前深度学习模型参数量大的背景下，是压缩模型打包是很困难也是浪费时间的方式，所以当前能够较为舒服的使用的方式就是使用torch-model-archiver生成handler.py文件，去编写控制流程。\n但不管是当前的大模型还是之前的深度学习模型，其处理流程都是类似的，用户发送请求，接着进行前处理、模型推理和后处理，然后再将生成的结果返回给用户，这里的具体细节由于上一篇已经讲过了，所以在这里不再赘述。除此之外，在上一篇还简单提到了，可以对模型进行ONNX和TensorRT等形式的转换，这一篇会深入去聊一聊。\n不过这篇文章最主要的是，深入handler.py文件中的BaseHandler类，除了看看对用户的请求处理之外，我们还能够干什么。\nBaseHandler类总览正如之前所说，模型服务最核心的逻辑都在handler.py文件中，而在该文件中最重要的就是编写class Handler(BaseHandler)类方法，所以在这里展开来看这个类到底是什么。\n首先，这个类是在base_handler.py文件中，在这个文件中，定义了很多与模型部署相关的组件和函数，具体来看：\n\n导入部分：有日志模块logging和自定义时间记录模块timed，接着就是一些与部署组件相关的模块，诸如torch.compile、openvino、onnxruntime和torch_tensorrt等模块。\nhandler.py类的函数：\n模型初始化相关的各种init、load等开头的函数：主要负责控制逻辑初始化和加载模型功能\n接着就是模型处理的:preprocess、inference和postprocess：也就是前处理，模型处理和后处理。\n\n\n以及一些工具函数：handler、profiler等等。\n\n总之整体的架构并不复杂，核心仍然是围绕着前处理，模型推理和后处理这三个步骤来的，在服务启动之前的可以叫做准备工作；对服务进行监控的比如timed可以叫做性能监控；在服务退出的时候，做回收处理，但这里似乎没有，可以理解到，深度学习模型服务中间不产生额外的文件，而作为一种函数性的处理方式在运行。\n所以，上述的关系就可以这样表述：\n\n可以看到，其主要有两部分，一部分就是模型启动，包括模型加载和预处理(可能存在模型需要转换等)，接着就是针对模型进行优化，首先需要进行性能检测，针对性能分析的结果进行模型调优，直到模型能够比较好地响应需求；另一方面，当模型作为一个服务部署提供服务的时候，仍然需要进行性能检测，此时则是进行动态调整和针对业务的进一步地再优化，比如当业务较多的时候通过负载压力来进行扩容，或者是通过性能检测发现存在的性能不足的问题，针对性地进行优化，从而能够以较小成本提供较多的提升。\n告一段落的TorchServe其实到这里，Torchserve已经可以告一段落了。也正如Torchserve那样，它出发点是以PyTorch为主要启动器(当然也支持ONNX、TensorRT、OpenVino等模型模型框架，当然在自定义的前提下，也能够引入其他的部署模型框架)，同时在Pytorch-2.x版本中，还支持torch.compile直接对模型进行优化，以便快速构建小型深度学习模型的可快速移植可快速启动，以及搭配其工作流，将不同的模型搭配使用，构建一个复杂的模型工作流处理任务。\n但这也随着大模型的到来，虽然在最近更新的版本中支持了huggingface和vllm等大模型相关的组件，对比其他的深度学习推理框架，比如TFserve其本身是因为TensorFlow的消失而跟着一起消失；Kserve，主要是以容器化的方式来支持模型服务运行(自定义更强)；TritonServer针对NIVIDIA有一定的优化，但个人也没用过不太好评价；BentoML和Kserve类似，主要是集中在容器化的工作。\n所以从这个角度来看，Torchserve其实是一个很尴尬的局面，似乎它的发力点集中在小模型，以及小模型的配合上，所以当大模型登场（大模型一般会涉及到分布式部署），此时Torchserve就没办法很好地控制。而对于服务控制，特别是多个模型服务控制，其实就可以将他们看做是服务，所以多个服务的管理，使用容器化进行管理会比较好；另一方面，其本质上并不对针对模型进行优化，而只是提供基础通用的模型优化，如果对性能有极致地追求，仍然需要手工优化。\n简单来说：\n\n模型服务：\n在大模型视角下，之前主打小模型以及小模型的配合就是累赘。\n而针对大模型需要的分布式相关的功能并没有提供\n\n\n模型推理：\n而对于性能上，在pyTorch的框架下提供部署和优化，如果需要极致性能追求，仍然需要手工完成。\n在大模型下的优化，就不单纯是直接优化那么简单。\n\n\n\n所以，更好的选择就变成了，以分布式为主的容器化模型服务与通用基础、主流推理框架和自定义极致优化的方式搭配会更好。\n后续的安排所以关于TorchServe的内容就到此结束了，虽然里面有很多内容还可以继续深挖，但实际上，这些技术单拿出来也可以继续讲，而不需要依赖这个推理系统框架，但从入门的角度来看，从一个推理系统框架来进行入门其实是一个不算差的选择，因为首先它能够很快地提供一个快速上线的模板，熟悉了写基础模型服务以后，就可以开展两个方面的深入：\n\n容器化的推理框架模型：从当前活跃的推理系统框架来看，更多是侧重容器化管理，而主语模型能够提供什么服务，则并不关心，更多是模型作为一个服务来看待。\n模型部署与推理优化：而至于模型本身，特别是指针对已经训练好的模型进行部署与推理优化，其目标则是在已有的模型功能和参数的基础上，一方面实现基础的功能服务之外，另一方面针对推理性能上的问题进行优化。\n\n所以后续这一系列的文章则是针对模型部署与推理优化作为主要讨论的方向，针对深度学习模型进行深入挖掘，而中间应该会涉有其他的以容器为主的推理系统框架介绍，大模型背景下的分布式式计算等相关技术。\n","tags":["推理系统"]},{"title":"深度学习模型部署浅思","url":"/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%8E%A8%E7%90%86%E7%B3%BB%E7%BB%9F/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2%E6%B5%85%E6%80%9D/","content":"从深度学习模型Web服务展开来讲对当前深度学习模型思考主要还是针对对应的数据集上如何构建模型，训练模型，以及模型在相关数据集（测试集）上的评估指标对模型进行评估。自然，从这一条线出发，考虑的就是模型如何设计以及相关的设计如何达到既定的目标。\n而在具体生产生活中，深度学习模型迭代到一个合理版本的模型后，自然考虑的就是如何提供相应的模型处理服务以供大家使用。对于个人或是中小型公司一般而言会采用交互界面和模型处理逻辑结合的方式提供服务，目前，主要有三个方案可以选择：\n一、Gradio + 深度学习模型如果我们将深度学习服务开发看做传统的Web服务开发，那么Gradio可以看做是前端和API的结合体，而模型与模型的前后处理则是是后端处理模块。Gradio可以让开发者快速开发出一个拥有基础交互方式的界面，以提供给用户一个前端交互界面能够与相关模型进行交互，而不是直接命令行（因为如果是深度学习模型训练那一条线，大部分情况都需要和命令行交互）。\n所以最快的构建方式是，利用Gradio快速搭建前端交互逻辑，运行模型，利用Gradio所自带的API服务公开自己的Web服务。\n但这可能存在一个问题是，当用户比较多的时候，由于传统的深度学习模型无法进行异步执行，导致后一个用户需要等待模型处理完前一个用户的需求才能够执行后续用户的需求。\n不过，在这里可以略微改进一点的是，增加一个等待请求池，其功能是在模型正在处理当前用户需求的情况下，将新来的用户请求放入等待请求池，给定一个批次（batch），每次取这些批次的请求一起丢入模型进行处理，增大整个模型运行的吞吐量。\n二、前端 + API + 模型（由于这里主要讨论的是Web服务，事实上，在这里还有另一种提供服务的方式是，开发桌面应用程序，应用程序启动的时候，模型也启动，并且根据对应的电脑硬件选择CPU还是GPU运行。）Gradio虽然提供了一个快速开发前端界面的功能，但是对真实场景的前端需求是不足以满足涉及需求的，因为Gradio设计初衷仅仅只是能够让模型能够有一个基础的交互界面，事实上并不能作为“真正”的前端开发工具。所以为了能够提供给用户一个更好的交互界面，当然仍需要回到传统的前端开发框架上。\n那么这里就需要不同语言之间进行交互，因为传统的前端开发经常使用Vue.js + Java，而由于大部分的深度学习是基于python代码，所以对于模型的运行和部署主要还是在python代码上，就需要从python代码中提供API服务，常见的有Flask和Fastapi快速提供一个可用的API接口，以供前端调用。\n不过在这里，还可以理解其他情况：\n\n  \n    \n      两种情况\n\n    \n    \n      \n只开发前端那么所有相关的模型则由互联网上的运营商所提供。此时还要注意一点的是，由于相关的模型运营厂商只提供一个基础模型的调用，模型的前处理和后处理仍然需要前端完成。\n\n只提供模型服务这一类相当于将自己放在模型厂商的位置上，可以提供常用模型，也可以提供个性化模型设计。将相关的模型服务包装成API提供给用户进行调用。\n\n\n\n    \n  \n\n其实走到这一步，已经基本上满足大部分应用的开发需求，因为只需要将模型看做是一个代码中的一个处理函数，就可以融入到之前的开发思路上。\n但从实际的场景来看，由于深度学习模型本身参数较大，特别是在2023年开启的大模型时代，虽然其模型能力很强，但其运行成本也相对传统的算法处理函数更多。所以在实际开发中，就不得不需要考虑运行模型所带来的成本问题，以及如何降低模型运行的成本。\n同时由于深度学习模型存在批次问题，或者说，由于大部分的深度学习是矩阵乘积的形式：，在较小的下，模型运行时间是差不多，因为此时的计算瓶颈仍然是通信瓶颈，所以同时处理更多的数据并不会增加模型的处理时间。\n而另一方面，如果一个Web服务提供多个模型的服务，还需要考虑当前的设备是否能够支持多个模型运行，以及多个模型运行是否会导致模型之间争夺资源的问题。\n当然，这些事情的考虑在模型服务提供厂商来说都可以解决，换句话说，如果负责前端开发就不需要关心这些事情，但如果需要自主模型部署则需要考虑。\n三、前端 + 模型推理框架所以，如果需要做到一个企业级的模型运行服务，或者至少能够尽可能让设备运行起来的服务，在这里就可以采用模型推理框架。\n相关的模型推理框架一方面能够快速提供对应的API服务，同时针对模型的批次特点进行优化，同时对多个模型运行有负载均衡和调度的优化，能够根据当前硬件资源进行自主调度。但最现实的情况也是，当硬件性能有限的情况下，留给调度和性能平衡的空间就越小，硬件资源多的情况下，留给平衡的空间就大。\n在这里简单列一下深度学习模型需要的推理服务框架的特点（不一定全）：\n\n  \n    \n      特点\n\n    \n    \n      \n能够合并请求在一个批次中进行推理。这应该是最常见的需求，不管是从训练的角度来说，模型可以一次性计算多个批次的数据，还是有强大计算能力的GPU，它在运行模型，可以一次性计算多个批次的数据而不影响模型推理速度，合并请求在一个批次都应该是一个很重要的能力。\n\n热启动模型。与Flask和FastAPI不一样的是，推理服务框架本身可以单独启动，中间的模型可以在服务框架启动以后再进行启动，或启动以后注销。这能够加速模型服务的开发。\n\n支持模型优化。由于模型推理服务，是不会有类似模型训练一样，需要梯度计算（但有一些服务提供微调服务，是需要这部分的内容的。）所以可以节省一定的计算量。类似地，如何更好地与硬件结合起来也是当前主流的研究方向，类似支持onnx等格式转换和运行。只不过有一些情况，相关硬件和推理框架配合得不是特别好，只能使用一个比较低效方式运行模型。\n\n支持模型前后处理。类似CV模型，传入的图片数据需要做变换，以及图像处理以后也需要做处理，在一些轻量级的模型推理框架，这一部分也是能够在框架内部处理，并做成一个服务。\n\n\n\n    \n  \n不过，由于我目前没有搜集太多关于服务推理框架的内容，所以在这里也只是做一个简单的收录：\n\n\n\n服务框架\n时间\n特点\n仓库地址\n\n\n\nTensorFlow Serving\n2016\n只支持TensorFlow，但TF已经逐渐式微\n链接\n\n\nTritonServe\n2018\n全都支持，但入门稍难\n链接\n\n\nBentoML\n2019\n全都支持\n链接\n\n\nKServe(原KFServing)\n2020\n全都支持\n链接\n\n\nTorchServe\n2020\n只支持PyTorch，入门稍简单，但文档比较差(已停止维护)\n链接\n\n\n后续个人会拿一个到几个作为入门熟悉模型部署这一内容。\n","tags":["推理系统"]}]